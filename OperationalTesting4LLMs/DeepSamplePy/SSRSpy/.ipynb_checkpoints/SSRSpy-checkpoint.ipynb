{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c63861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_800.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the datasets and budgets\n",
    "datasets = [\"imdb300AuxDS\", \"imdbAuxDS\", \"SSTtestAuxDS\"]\n",
    "aux_variables = [\"Confidence_Score\", \"Prediction_Entropy\", \"Similarity_Score\", \"DSA\", \"LSA\"]\n",
    "budgets = [50, 100, 200, 400, 800]\n",
    "root_dir = \"../dataset\"\n",
    "output_dir = \"SSRSpy/SSRSpyResults\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"Load data and convert 'Outcome' to binary.\"\"\"\n",
    "    df = pd.read_csv(os.path.join(root_dir, filename))\n",
    "    df['Outcome'] = df['Outcome'].apply(lambda x: 1 if x.lower() == 'pass' else 0)\n",
    "    return df\n",
    "\n",
    "def stratified_sampling(df, budget, aux_var, num_partitions=10):\n",
    "    \"\"\"Perform stratified sampling based on Neyman allocation.\"\"\"\n",
    "    try:\n",
    "        df['partition'] = pd.qcut(df[aux_var], q=num_partitions, labels=False, duplicates='drop')\n",
    "    except ValueError:\n",
    "        df['partition'] = pd.cut(df[aux_var], bins=num_partitions, labels=False, duplicates='drop')\n",
    "\n",
    "    std_devs = df.groupby('partition')[aux_var].std().fillna(0)\n",
    "    sizes = df.groupby('partition').size()\n",
    "    prop_allocations = (std_devs / std_devs.sum()) * sizes\n",
    "    sample_sizes = np.floor(prop_allocations / prop_allocations.sum() * budget).astype(int)\n",
    "\n",
    "    while sample_sizes.sum() < budget:\n",
    "        sample_sizes[sample_sizes.idxmax()] += 1\n",
    "\n",
    "    samples = []\n",
    "    for partition, size in sample_sizes.items():\n",
    "        available_size = min(size, sizes[partition])\n",
    "        if available_size > 0:\n",
    "            samples.append(df[df['partition'] == partition].sample(n=available_size, replace=False))\n",
    "\n",
    "    return pd.concat(samples)\n",
    "\n",
    "def simulate_accuracy_and_failures(sampled_data):\n",
    "    \"\"\"Calculate accuracy and count failures.\"\"\"\n",
    "    failures = sampled_data['Outcome'].value_counts().get(0, 0)\n",
    "    total = len(sampled_data)\n",
    "    accuracy = (total - failures) / total if total > 0 else 0\n",
    "    return accuracy, failures\n",
    "\n",
    "# Main processing loop\n",
    "for dataset in datasets:\n",
    "    df = load_data(dataset + '.csv')\n",
    "    for aux_var in aux_variables:\n",
    "        for budget in budgets:\n",
    "            output_filename = f\"{output_dir}/{dataset}_{aux_var}_{budget}.txt\"\n",
    "            with open(output_filename, 'w') as f:\n",
    "                f.write(\"accuracy,failures\\n\")\n",
    "                for _ in range(30):\n",
    "                    try:\n",
    "                        sampled_data = stratified_sampling(df, budget, aux_var)\n",
    "                        accuracy, failures = simulate_accuracy_and_failures(sampled_data)\n",
    "                        f.write(f\"{accuracy},{failures}\\n\")\n",
    "                    except Exception as e:\n",
    "                        f.write(f\"Error: {str(e)}\\n\")\n",
    "            print(f\"Sampled data saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae13522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Confidence_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Prediction_Entropy_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_Similarity_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_DSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdb300AuxDS_LSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Confidence_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Prediction_Entropy_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_Similarity_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_DSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/imdbAuxDS_LSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Confidence_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Prediction_Entropy_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_Similarity_Score_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_DSA_800.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_50.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_100.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_200.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_400.txt\n",
      "Sampled data saved to SSRpy/SSRpyResults/SSTtestAuxDS_LSA_800.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the datasets and budget constraints\n",
    "datasets = [\"imdb300AuxDS\", \"imdbAuxDS\", \"SSTtestAuxDS\"]\n",
    "aux_variables = [\"Confidence_Score\", \"Prediction_Entropy\", \"Similarity_Score\", \"DSA\", \"LSA\"]\n",
    "budgets = [50, 100, 200, 400, 800]\n",
    "root_dir = \"../dataset\"\n",
    "output_dir = \"SSRSpy/SSRSpyResults\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"Load data from CSV files and convert 'Outcome' to binary.\"\"\"\n",
    "    df = pd.read_csv(os.path.join(root_dir, filename))\n",
    "    df['Outcome'] = df['Outcome'].apply(lambda x: 1 if x.lower() == 'pass' else 0)\n",
    "    return df\n",
    "\n",
    "def stratified_sampling(df, budget, aux_var, num_partitions=10):\n",
    "    \"\"\"Perform stratified sampling with Neyman allocation.\"\"\"\n",
    "    try:\n",
    "        df['partition'] = pd.qcut(df[aux_var], q=num_partitions, labels=False, duplicates='drop')\n",
    "    except ValueError:\n",
    "        df['partition'] = pd.cut(df[aux_var], bins=num_partitions, labels=False)\n",
    "    \n",
    "    groupby_partition = df.groupby('partition')[aux_var]\n",
    "    std_devs = groupby_partition.std().fillna(0)\n",
    "    sizes = groupby_partition.size()\n",
    "    prop_allocations = (std_devs / std_devs.sum()) * sizes\n",
    "    sample_sizes = np.floor(prop_allocations / prop_allocations.sum() * budget).astype(int)\n",
    "\n",
    "    while sample_sizes.sum() < budget:\n",
    "        sample_sizes[sample_sizes.idxmax()] += 1\n",
    "\n",
    "    samples = []\n",
    "    for partition, size in sample_sizes.items():\n",
    "        available_size = min(size, sizes[partition])\n",
    "        if available_size > 0:\n",
    "            samples.append(df[df['partition'] == partition].sample(n=available_size, replace=False))\n",
    "\n",
    "    return pd.concat(samples)\n",
    "\n",
    "def simulate_accuracy_and_failures(sampled_data):\n",
    "    \"\"\"Calculate accuracy and number of failures.\"\"\"\n",
    "    failures = sampled_data['Outcome'].value_counts().get(0, 0)\n",
    "    total = len(sampled_data)\n",
    "    accuracy = (total - failures) / total if total > 0 else 0\n",
    "    return accuracy, failures\n",
    "\n",
    "# Run the stratified sampling for each dataset, auxiliary variable, and budget\n",
    "for dataset in datasets:\n",
    "    df = load_data(dataset + '.csv')\n",
    "    for aux_var in aux_variables:\n",
    "        for budget in budgets:\n",
    "            output_filename = f\"{output_dir}/{dataset}_{aux_var}_{budget}.txt\"\n",
    "            with open(output_filename, 'w') as file:\n",
    "                file.write(\"accuracy,failures\\n\")\n",
    "                for _ in range(30):  # Perform sampling 30 times for robust statistics\n",
    "                    sampled_data = stratified_sampling(df, budget, aux_var)\n",
    "                    accuracy, failures = simulate_accuracy_and_failures(sampled_data)\n",
    "                    file.write(f\"{accuracy},{failures}\\n\")\n",
    "            print(f\"Sampled data saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa832e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
